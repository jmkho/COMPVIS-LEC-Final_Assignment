{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.\t[LO 2] Build Visual Vocabulary from the dataset using the Visual Bag of Words algorithm. Explain comprehensively how the algorithms work! \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step is to import the libraries we are using. We will need the KMeans cluster function, provided by scikit-learn in order to create the word clusters and to compute the centroid for each clusters we will need to calculate the distance from each point to the clusters, thus we also need the distance function provided by scipy.\n",
    "Other libraries will be used for image processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np \n",
    "from scipy.spatial import distance\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to load the dataset we will use. Here I'm using a local dataset and thus we need to import them beforehand (dataset can be accessed through this link: ).\n",
    "Loading the dataset will be done both for the training and testing data, storing them into a dictionary as the class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(path):\n",
    "    image_dict = {}\n",
    "    for animal_type in os.listdir(path):\n",
    "        animal_type_image = []\n",
    "        type_path = f\"{path}/{animal_type}\"\n",
    "        for image in os.listdir(type_path): \n",
    "            img = cv2.imread(f\"{type_path}/{image}\", 0)\n",
    "            if img is not None: \n",
    "                img = cv2.resize(img, (100,100))\n",
    "                animal_type_image.append(img)\n",
    "        image_dict[animal_type] = animal_type_image\n",
    "    return image_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = load_images('cat-and-dog/training_set/training_set/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = load_images('cat-and-dog/test_set/test_set/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the function to get local features of the image using SIFT. In one dataset consists of two categories: cat and dog. These categories will be iterated separatedly, by getting the keypoints and descriptors for every image in both categories (cat and dog). The descriptor for all images will be combined in the descriptors list, while the descriptors for specific class will be stored in the sift_vectors dictionary. This function will return a list that has 2 values; the first value is the combined descriptors of all images and the second value is the visual dictionary of our descriptors from specific classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sift_features(dataset):\n",
    "    sift_vectors = {}\n",
    "    descriptors = []\n",
    "    sift = cv2.SIFT_create()\n",
    "\n",
    "    for category, animal_img in dataset.items():\n",
    "        features = []\n",
    "        for img in animal_img:\n",
    "            kp, desc = sift.detectAndCompute(img, None)\n",
    "            descriptors.extend(desc)\n",
    "            features.append(desc)\n",
    "        sift_vectors[category] = features\n",
    "\n",
    "    return [descriptors, sift_vectors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_sift = sift_features(train_set)\n",
    "descriptor_list = compute_sift[0]\n",
    "bovw_dictionary = compute_sift[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, after getting all the descriptors, we can pass it to the K-Means clustering algorithm to find the visual words, which are the center points for each cluster. here, we set the K (cluster groups) to 100. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(k, desc):\n",
    "    kmeans = KMeans(n_clusters=k, n_init=10)\n",
    "    kmeans.fit(desc)\n",
    "    visual_bow = kmeans.cluster_centers_\n",
    "\n",
    "    return visual_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_bow = kmeans(100, descriptor_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.\t[LO 3] Use K-NN to predict the object (i.e., dog or cat) and explain the results!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As what we did with the training data, we will also compute the features for the test dataset and store it into a dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sift = sift_features(test_set)\n",
    "test_dictionary = test_sift[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the histogram for train and test dataset so we may compare the accuracy of the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_hist(bovw, centroid):\n",
    "    feature_dict = {}\n",
    "    for category, value in bovw.items():\n",
    "        histograms = []\n",
    "        for img in value: \n",
    "            hist = cv2.calcHist([img], [0], None, [256], [0,256])\n",
    "            histograms.append(hist)\n",
    "        feature_dict[category] = hist\n",
    "    return feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bovw_hist_train = data_hist(bovw_dictionary, visual_bow)\n",
    "bovw_hist_test = data_hist(test_dictionary, visual_bow)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will compute the prediction for the test images using the KNN method. Below I had it done from scratch.\n",
    "\n",
    "So first, we will initiate the test_count as 0 (to count the times we run the test), correct as 0 (to keep track the correct predictions) and initializing the cat_or_dog dictionary, to store the prediction results. \n",
    "\n",
    "After that we will start iterating the test dataset. Previously we stored it in a dictionary, where the label marks the category of the image and the value are the images. We also take the test_category of the images because later on we will be counting the correctness of the prediction labels for each image in the test dataset. \n",
    "\n",
    "So now we will conduct the iteration for all the test images. First we will also initiate three variables: predict (for the starting checkpoint), min_dist (to keep track on the minimum distance from the centroid) and pred_category (which later on will be replaced with the predicted category result).\n",
    "\n",
    "Then we can count the distance between our train and test image keypoints using the Euclidean distance. The first iteration distance will be stored as the min_dist, while if during the next iterations we found another shorter distance than the previous one, it will replace the previous minimum distance. \n",
    "[IMPORTANT!] Don't forget to store the category of the train image that has the minimum distance with the test image. The shortest distance between the test image and the train image will be considered to be one categorized. \n",
    "\n",
    "After iterating through all the train images, we will check whether the current predicted category with the test category (the one we store during the start of the test_loop) has the same label, we will add one to our correct variable and to the current category we are predicting (cat/dog). \n",
    "\n",
    "This function will return a list consists of test_count (times we run the function), correct (number of correctly predicted labels), and the cat_or_dog dictionary (contains the number of predicted test images for each category)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(images, test):\n",
    "    test_count = 0\n",
    "    correct = 0\n",
    "    cat_or_dog = {}\n",
    "\n",
    "    for test_category, test_value in test.items():\n",
    "        cat_or_dog[test_category] = [0,0]\n",
    "\n",
    "        # iterating the images in test dataset\n",
    "        for test_img in test_value:\n",
    "            predict = 0\n",
    "            min_dist = 0\n",
    "            pred_category = \"animal\"\n",
    "            # iterating the images in train dataset \n",
    "            for train_category, train_value in images.items():\n",
    "                for train_img in train_value: \n",
    "                    if (predict==0): # setting the first data \n",
    "                        min_dist = distance.euclidean(test_img, train_img)\n",
    "                        pred_category = train_category\n",
    "                        predict += 1\n",
    "                    else: # after the first data \n",
    "                        dist = distance.euclidean(test_img, train_img)\n",
    "\n",
    "                        if (dist < min_dist): \n",
    "                            min_dist = dist\n",
    "                            pred_category = train_category\n",
    "\n",
    "            if (test_category == pred_category):\n",
    "                correct += 1\n",
    "                cat_or_dog[test_category][0] += 1\n",
    "            test_count += 1\n",
    "            cat_or_dog[test_category][1] += 1\n",
    "\n",
    "    return [test_count, correct, cat_or_dog]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = knn(bovw_hist_train, bovw_hist_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last step is to check the accuracy of our program. To do that we will count the number of correctly predicted test images divided with the number of test we made, which will result in the accuracy average of the test image. \n",
    "We will also print out the accuracy for each class category (cat & dog) by dividing the result of correctly predicted test images with the number of test made for that category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(result):\n",
    "    acc_avg = (result[1] / result[0]) * 100 #correct prediction / number of test made \n",
    "    print(f\"Average accuracy: {acc_avg}%\")\n",
    "    print(\"Class based on accuracy: \")\n",
    "    for category, value in result[2].items():\n",
    "        print(f\"Class {category}: {value[0]/value[1] * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 50.9765625%\n",
      "Class based on accuracy: \n",
      "Class cats: 84.765625%\n",
      "Class dogs: 17.1875%\n"
     ]
    }
   ],
   "source": [
    "accuracy(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test counts: 512 || Correct Prediction: 261\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test counts: {result[0]} || Correct Prediction: {result[1]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results above we can see that the average accuracy is 50.977%, which can still be tuned more to get better results especially for the dogs dataset, due to the accuracy for the cats category is rather well (84.766%) while the dogs category still has a low accuracy score (17.188%)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4fda8514bed4dbac83cc795c3014346393b2c62b99073a4a957f0b6e4226b84"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
